{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"03_Sentiment - XLM-T - Fine-tuned on custom datasets.ipynb","provenance":[{"file_id":"1IAA1h8u53O1hi9807u7oOFuT3728N0-n","timestamp":1643809386219},{"file_id":"12JuNVT-j_vQzIF9qEpRXFNqzKXCYgTrB","timestamp":1619639735281},{"file_id":"https://github.com/huggingface/notebooks/blob/master/transformers_doc/pytorch/custom_datasets.ipynb","timestamp":1619569772905}],"collapsed_sections":[]},"language_info":{"name":"python"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# Install Dependencies"],"metadata":{"id":"Nfly6ImSnJOx"}},{"cell_type":"code","metadata":{"id":"nKftOu9fyC8R","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1645095683001,"user_tz":-60,"elapsed":23069,"user":{"displayName":"Amalia Temneanu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07587986521191248081"}},"outputId":"f4054496-ff2b-4ff1-fafd-971fd8960fa2"},"source":["!pip install --upgrade pip\n","!pip install sentencepiece\n","!pip install datasets\n","!pip install transformers"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: pip in /usr/local/lib/python3.7/dist-packages (21.1.3)\n","Collecting pip\n","  Downloading pip-22.0.3-py3-none-any.whl (2.1 MB)\n","\u001b[K     |████████████████████████████████| 2.1 MB 29.0 MB/s \n","\u001b[?25hInstalling collected packages: pip\n","  Attempting uninstall: pip\n","    Found existing installation: pip 21.1.3\n","    Uninstalling pip-21.1.3:\n","      Successfully uninstalled pip-21.1.3\n","Successfully installed pip-22.0.3\n","Collecting sentencepiece\n","  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m53.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: sentencepiece\n","Successfully installed sentencepiece-0.1.96\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0mCollecting datasets\n","  Downloading datasets-1.18.3-py3-none-any.whl (311 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.7/311.7 KB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from datasets) (4.11.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets) (1.21.5)\n","Collecting huggingface-hub<1.0.0,>=0.1.0\n","  Downloading huggingface_hub-0.4.0-py3-none-any.whl (67 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.0/67.0 KB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets) (21.3)\n","Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (4.62.3)\n","Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.4)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2.23.0)\n","Requirement already satisfied: pyarrow!=4.0.0,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (6.0.1)\n","Collecting xxhash\n","  Downloading xxhash-2.0.2-cp37-cp37m-manylinux2010_x86_64.whl (243 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m243.9/243.9 KB\u001b[0m \u001b[31m27.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets) (0.70.12.2)\n","Collecting fsspec[http]>=2021.05.0\n","  Downloading fsspec-2022.1.0-py3-none-any.whl (133 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.2/133.2 KB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.3.5)\n","Collecting aiohttp\n","  Downloading aiohttp-3.8.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m48.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.13)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.10.0.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.4.2)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets) (3.0.7)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2021.10.8)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (1.24.3)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (21.4.0)\n","Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (2.0.11)\n","Collecting yarl<2.0,>=1.0\n","  Downloading yarl-1.7.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (271 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m271.8/271.8 KB\u001b[0m \u001b[31m27.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting aiosignal>=1.1.2\n","  Downloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n","Collecting frozenlist>=1.1.1\n","  Downloading frozenlist-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m144.8/144.8 KB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3\n","  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n","Collecting multidict<7.0,>=4.5\n","  Downloading multidict-6.0.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (94 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.8/94.8 KB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting asynctest==0.13.0\n","  Downloading asynctest-0.13.0-py3-none-any.whl (26 kB)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->datasets) (3.7.0)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2018.9)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n","Installing collected packages: xxhash, multidict, fsspec, frozenlist, asynctest, async-timeout, yarl, huggingface-hub, aiosignal, aiohttp, datasets\n","Successfully installed aiohttp-3.8.1 aiosignal-1.2.0 async-timeout-4.0.2 asynctest-0.13.0 datasets-1.18.3 frozenlist-1.3.0 fsspec-2022.1.0 huggingface-hub-0.4.0 multidict-6.0.2 xxhash-2.0.2 yarl-1.7.2\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0mCollecting transformers\n","  Downloading transformers-4.16.2-py3-none-any.whl (3.5 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.5/3.5 MB\u001b[0m \u001b[31m84.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.4.0)\n","Collecting pyyaml>=5.1\n","  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m596.3/596.3 KB\u001b[0m \u001b[31m52.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.4.2)\n","Collecting sacremoses\n","  Downloading sacremoses-0.0.47-py2.py3-none-any.whl (895 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m895.2/895.2 KB\u001b[0m \u001b[31m60.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.5)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n","Collecting tokenizers!=0.11.3,>=0.10.1\n","  Downloading tokenizers-0.11.5-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m87.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.7)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.7.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Installing collected packages: tokenizers, sacremoses, pyyaml, transformers\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","Successfully installed pyyaml-6.0 sacremoses-0.0.47 tokenizers-0.11.5 transformers-4.16.2\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0m"]}]},{"cell_type":"markdown","metadata":{"id":"_ykXokStcwGz"},"source":["# Fine-tuning XLM-T\n","\n","This notebook was modified from https://huggingface.co/transformers/custom_datasets.html"]},{"cell_type":"code","metadata":{"id":"Y5f1fFbETSbM"},"source":["from transformers import AutoTokenizer\n","from transformers import AutoModelForSequenceClassification, Trainer, TrainingArguments\n","import torch\n","\n","import numpy as np\n","import pandas as pd\n","from sklearn.metrics import classification_report\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","os.environ['CUDA_LAUNCH_BLOCKING']='1'\n","\n","torch.cuda.empty_cache()"],"metadata":{"id":"XwtQMDZbmiIR"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dtj1poj8yC8b"},"source":["## Parameters"]},{"cell_type":"code","metadata":{"id":"r3OxewRLFaK1"},"source":["LR = 2e-5\n","EPOCHS = 1\n","BATCH_SIZE = 32\n","MODEL = \"cardiffnlp/twitter-xlm-roberta-base-sentiment\" # use this to finetune the sentiment classifier\n","MAX_TRAINING_EXAMPLES = -1 # set this to -1 if you want to use the whole training set"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XWqZ7LGMFeHV"},"source":["## Data"]},{"cell_type":"markdown","metadata":{"id":"a1A24j8pFhup"},"source":["We download the xml-t sentiment dataset (`UMSAB`).\n"]},{"cell_type":"code","metadata":{"id":"fvM2mCi2yC8c","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1644846200529,"user_tz":-60,"elapsed":2000,"user":{"displayName":"Amalia Temneanu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07587986521191248081"}},"outputId":"545ef0ee-0a07-41cd-d127-e7973b61c4a4"},"source":["# loading dataset for UMSAB's all 8 languages\n","\n","files = \"\"\"test_labels.txt\n","test_text.txt\n","train_labels.txt\n","train_text.txt\n","val_labels.txt\n","val_text.txt\"\"\".split('\\n')\n","\n","for f in files:\n","  p = f\"https://raw.githubusercontent.com/cardiffnlp/xlm-t/main/data/sentiment/all/{f}\"\n","  !wget $p"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["--2022-02-14 13:43:18--  https://raw.githubusercontent.com/cardiffnlp/xlm-t/main/data/sentiment/all/test_labels.txt\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.108.133, 185.199.110.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 13919 (14K) [text/plain]\n","Saving to: ‘test_labels.txt.1’\n","\n","\rtest_labels.txt.1     0%[                    ]       0  --.-KB/s               \rtest_labels.txt.1   100%[===================>]  13.59K  --.-KB/s    in 0s      \n","\n","2022-02-14 13:43:18 (71.4 MB/s) - ‘test_labels.txt.1’ saved [13919/13919]\n","\n","--2022-02-14 13:43:18--  https://raw.githubusercontent.com/cardiffnlp/xlm-t/main/data/sentiment/all/test_text.txt\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 654172 (639K) [text/plain]\n","Saving to: ‘test_text.txt.1’\n","\n","test_text.txt.1     100%[===================>] 638.84K  --.-KB/s    in 0.03s   \n","\n","2022-02-14 13:43:18 (20.7 MB/s) - ‘test_text.txt.1’ saved [654172/654172]\n","\n","--2022-02-14 13:43:19--  https://raw.githubusercontent.com/cardiffnlp/xlm-t/main/data/sentiment/all/train_labels.txt\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 29423 (29K) [text/plain]\n","Saving to: ‘train_labels.txt.1’\n","\n","train_labels.txt.1  100%[===================>]  28.73K  --.-KB/s    in 0.001s  \n","\n","2022-02-14 13:43:19 (22.0 MB/s) - ‘train_labels.txt.1’ saved [29423/29423]\n","\n","--2022-02-14 13:43:19--  https://raw.githubusercontent.com/cardiffnlp/xlm-t/main/data/sentiment/all/train_text.txt\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 1429312 (1.4M) [text/plain]\n","Saving to: ‘train_text.txt.1’\n","\n","train_text.txt.1    100%[===================>]   1.36M  --.-KB/s    in 0.04s   \n","\n","2022-02-14 13:43:19 (38.4 MB/s) - ‘train_text.txt.1’ saved [1429312/1429312]\n","\n","--2022-02-14 13:43:19--  https://raw.githubusercontent.com/cardiffnlp/xlm-t/main/data/sentiment/all/val_labels.txt\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.111.133, 185.199.109.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 5183 (5.1K) [text/plain]\n","Saving to: ‘val_labels.txt.1’\n","\n","val_labels.txt.1    100%[===================>]   5.06K  --.-KB/s    in 0s      \n","\n","2022-02-14 13:43:19 (69.9 MB/s) - ‘val_labels.txt.1’ saved [5183/5183]\n","\n","--2022-02-14 13:43:20--  https://raw.githubusercontent.com/cardiffnlp/xlm-t/main/data/sentiment/all/val_text.txt\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.111.133, 185.199.110.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 250100 (244K) [text/plain]\n","Saving to: ‘val_text.txt.1’\n","\n","val_text.txt.1      100%[===================>] 244.24K  --.-KB/s    in 0.01s   \n","\n","2022-02-14 13:43:20 (16.2 MB/s) - ‘val_text.txt.1’ saved [250100/250100]\n","\n"]}]},{"cell_type":"code","metadata":{"id":"DqNPXQg7GSn3"},"source":["dataset_dict = {}\n","for i in ['train','val','test']:\n","  dataset_dict[i] = {}\n","  for j in ['text','labels']:\n","    dataset_dict[i][j] = open(f\"{i}_{j}.txt\").read().split('\\n')\n","    if j == 'labels':\n","      dataset_dict[i][j] = [int(x) for x in dataset_dict[i][j]]\n","\n","if MAX_TRAINING_EXAMPLES > 0:\n","  dataset_dict['train']['text']=dataset_dict['train']['text'][:MAX_TRAINING_EXAMPLES]\n","  dataset_dict['train']['labels']=dataset_dict['train']['labels'][:MAX_TRAINING_EXAMPLES]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1IjMOsNSyC8d"},"source":["tokenizer = AutoTokenizer.from_pretrained(MODEL, use_fast=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Rp0llWQVyC8e","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1644846210521,"user_tz":-60,"elapsed":4218,"user":{"displayName":"Amalia Temneanu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07587986521191248081"}},"outputId":"719d55c9-10d4-4885-b26e-3a4ea354b174"},"source":["train_encodings = tokenizer(dataset_dict['train']['text'], truncation=True, padding=True)\n","val_encodings = tokenizer(dataset_dict['val']['text'], truncation=True, padding=True)\n","test_encodings = tokenizer(dataset_dict['test']['text'], truncation=True, padding=True)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"]}]},{"cell_type":"code","metadata":{"id":"1MzkHFG5yC8f"},"source":["class MyDataset(torch.utils.data.Dataset):\n","    def __init__(self, encodings, labels):\n","        self.encodings = encodings\n","        self.labels = labels\n","\n","    def __getitem__(self, idx):\n","        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n","        item['labels'] = torch.tensor(self.labels[idx])\n","        return item\n","\n","    def __len__(self):\n","        return len(self.labels)\n","\n","train_dataset = MyDataset(train_encodings, dataset_dict['train']['labels'])\n","val_dataset = MyDataset(val_encodings, dataset_dict['val']['labels'])\n","test_dataset = MyDataset(test_encodings, dataset_dict['test']['labels'])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"z_BTQBaJyC8g"},"source":["## Fine-tuning"]},{"cell_type":"markdown","metadata":{"id":"zmp35MgkyC8g"},"source":["The steps above prepared the datasets in the way that the trainer is expected. Now all we need to do is create a model\n","to fine-tune, define the `TrainingArguments`/`TFTrainingArguments` and\n","instantiate a `Trainer`/`TFTrainer`."]},{"cell_type":"code","metadata":{"id":"PGuho0dMyC8g"},"source":["training_args = TrainingArguments(\n","    output_dir='./results',                   # output directory\n","    num_train_epochs=EPOCHS,                  # total number of training epochs\n","    per_device_train_batch_size=BATCH_SIZE,   # batch size per device during training\n","    per_device_eval_batch_size=BATCH_SIZE,    # batch size for evaluation\n","    warmup_steps=100,                         # number of warmup steps for learning rate scheduler\n","    weight_decay=0.01,                        # strength of weight decay\n","    logging_dir='./logs',                     # directory for storing logs\n","    evaluation_strategy ='steps',\n","    eval_steps = 10,                          # evaluation and Save happens every 10 steps\n","    save_total_limit = 5,                     # only last 5 models are saved; older ones are deleted\n","    logging_steps=10,                         # when to print log\n","    load_best_model_at_end=True,              # load or not best model at the end\n",")\n","\n","num_labels = len(set(dataset_dict[\"train\"][\"labels\"]))\n","model = AutoModelForSequenceClassification.from_pretrained(MODEL, num_labels=num_labels)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"J7bArzixEAH-","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"6f4df1e6-5c52-45dc-ce4a-3c3906ccba92","executionInfo":{"status":"ok","timestamp":1644847843609,"user_tz":-60,"elapsed":568394,"user":{"displayName":"Amalia Temneanu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07587986521191248081"}}},"source":["trainer = Trainer(\n","    model=model,                              # the instantiated Transformers model to be trained\n","    args=training_args,                       # training arguments, defined above\n","    train_dataset=train_dataset,              # training dataset\n","    eval_dataset=val_dataset                  # evaluation dataset\n",")\n","\n","trainer.train()"],"execution_count":null,"outputs":[{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n","***** Running training *****\n","  Num examples = 14712\n","  Num Epochs = 1\n","  Instantaneous batch size per device = 32\n","  Total train batch size (w. parallel, distributed & accumulation) = 32\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 460\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='281' max='460' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [281/460 14:01 < 08:59, 0.33 it/s, Epoch 0.61/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>10</td>\n","      <td>0.629700</td>\n","      <td>0.746945</td>\n","    </tr>\n","    <tr>\n","      <td>20</td>\n","      <td>0.621800</td>\n","      <td>0.780576</td>\n","    </tr>\n","    <tr>\n","      <td>30</td>\n","      <td>0.609800</td>\n","      <td>0.779390</td>\n","    </tr>\n","    <tr>\n","      <td>40</td>\n","      <td>0.571000</td>\n","      <td>0.805704</td>\n","    </tr>\n","    <tr>\n","      <td>50</td>\n","      <td>0.577100</td>\n","      <td>0.813854</td>\n","    </tr>\n","    <tr>\n","      <td>60</td>\n","      <td>0.546000</td>\n","      <td>0.833704</td>\n","    </tr>\n","    <tr>\n","      <td>70</td>\n","      <td>0.602400</td>\n","      <td>0.792982</td>\n","    </tr>\n","    <tr>\n","      <td>80</td>\n","      <td>0.660600</td>\n","      <td>0.820057</td>\n","    </tr>\n","    <tr>\n","      <td>90</td>\n","      <td>0.704300</td>\n","      <td>0.756601</td>\n","    </tr>\n","    <tr>\n","      <td>100</td>\n","      <td>0.630100</td>\n","      <td>0.840525</td>\n","    </tr>\n","    <tr>\n","      <td>110</td>\n","      <td>0.555800</td>\n","      <td>0.864621</td>\n","    </tr>\n","    <tr>\n","      <td>120</td>\n","      <td>0.626400</td>\n","      <td>0.824904</td>\n","    </tr>\n","    <tr>\n","      <td>130</td>\n","      <td>0.664900</td>\n","      <td>0.829855</td>\n","    </tr>\n","    <tr>\n","      <td>140</td>\n","      <td>0.674800</td>\n","      <td>0.812260</td>\n","    </tr>\n","    <tr>\n","      <td>150</td>\n","      <td>0.655000</td>\n","      <td>0.848054</td>\n","    </tr>\n","    <tr>\n","      <td>160</td>\n","      <td>0.655600</td>\n","      <td>0.798248</td>\n","    </tr>\n","    <tr>\n","      <td>170</td>\n","      <td>0.685400</td>\n","      <td>0.786701</td>\n","    </tr>\n","    <tr>\n","      <td>180</td>\n","      <td>0.712600</td>\n","      <td>0.838528</td>\n","    </tr>\n","    <tr>\n","      <td>190</td>\n","      <td>0.696800</td>\n","      <td>0.770187</td>\n","    </tr>\n","    <tr>\n","      <td>200</td>\n","      <td>0.683600</td>\n","      <td>0.810535</td>\n","    </tr>\n","    <tr>\n","      <td>210</td>\n","      <td>0.664500</td>\n","      <td>0.865055</td>\n","    </tr>\n","    <tr>\n","      <td>220</td>\n","      <td>0.717800</td>\n","      <td>0.824962</td>\n","    </tr>\n","    <tr>\n","      <td>230</td>\n","      <td>0.635300</td>\n","      <td>0.799331</td>\n","    </tr>\n","    <tr>\n","      <td>240</td>\n","      <td>0.647300</td>\n","      <td>0.810953</td>\n","    </tr>\n","    <tr>\n","      <td>250</td>\n","      <td>0.689200</td>\n","      <td>0.809695</td>\n","    </tr>\n","    <tr>\n","      <td>260</td>\n","      <td>0.658000</td>\n","      <td>0.767072</td>\n","    </tr>\n","    <tr>\n","      <td>270</td>\n","      <td>0.648800</td>\n","      <td>0.800345</td>\n","    </tr>\n","  </tbody>\n","</table><p>\n","    <div>\n","      \n","      <progress value='32' max='81' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [32/81 00:08 < 00:13, 3.74 it/s]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["***** Running Evaluation *****\n","  Num examples = 2592\n","  Batch size = 32\n","***** Running Evaluation *****\n","  Num examples = 2592\n","  Batch size = 32\n","***** Running Evaluation *****\n","  Num examples = 2592\n","  Batch size = 32\n","***** Running Evaluation *****\n","  Num examples = 2592\n","  Batch size = 32\n","***** Running Evaluation *****\n","  Num examples = 2592\n","  Batch size = 32\n","***** Running Evaluation *****\n","  Num examples = 2592\n","  Batch size = 32\n","***** Running Evaluation *****\n","  Num examples = 2592\n","  Batch size = 32\n","***** Running Evaluation *****\n","  Num examples = 2592\n","  Batch size = 32\n","***** Running Evaluation *****\n","  Num examples = 2592\n","  Batch size = 32\n","***** Running Evaluation *****\n","  Num examples = 2592\n","  Batch size = 32\n","***** Running Evaluation *****\n","  Num examples = 2592\n","  Batch size = 32\n","***** Running Evaluation *****\n","  Num examples = 2592\n","  Batch size = 32\n","***** Running Evaluation *****\n","  Num examples = 2592\n","  Batch size = 32\n","***** Running Evaluation *****\n","  Num examples = 2592\n","  Batch size = 32\n","***** Running Evaluation *****\n","  Num examples = 2592\n","  Batch size = 32\n","***** Running Evaluation *****\n","  Num examples = 2592\n","  Batch size = 32\n","***** Running Evaluation *****\n","  Num examples = 2592\n","  Batch size = 32\n","***** Running Evaluation *****\n","  Num examples = 2592\n","  Batch size = 32\n","***** Running Evaluation *****\n","  Num examples = 2592\n","  Batch size = 32\n","***** Running Evaluation *****\n","  Num examples = 2592\n","  Batch size = 32\n","***** Running Evaluation *****\n","  Num examples = 2592\n","  Batch size = 32\n","***** Running Evaluation *****\n","  Num examples = 2592\n","  Batch size = 32\n","***** Running Evaluation *****\n","  Num examples = 2592\n","  Batch size = 32\n","***** Running Evaluation *****\n","  Num examples = 2592\n","  Batch size = 32\n","***** Running Evaluation *****\n","  Num examples = 2592\n","  Batch size = 32\n","***** Running Evaluation *****\n","  Num examples = 2592\n","  Batch size = 32\n","***** Running Evaluation *****\n","  Num examples = 2592\n","  Batch size = 32\n","***** Running Evaluation *****\n","  Num examples = 2592\n","  Batch size = 32\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='460' max='460' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [460/460 23:38, Epoch 1/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>10</td>\n","      <td>0.629700</td>\n","      <td>0.746945</td>\n","    </tr>\n","    <tr>\n","      <td>20</td>\n","      <td>0.621800</td>\n","      <td>0.780576</td>\n","    </tr>\n","    <tr>\n","      <td>30</td>\n","      <td>0.609800</td>\n","      <td>0.779390</td>\n","    </tr>\n","    <tr>\n","      <td>40</td>\n","      <td>0.571000</td>\n","      <td>0.805704</td>\n","    </tr>\n","    <tr>\n","      <td>50</td>\n","      <td>0.577100</td>\n","      <td>0.813854</td>\n","    </tr>\n","    <tr>\n","      <td>60</td>\n","      <td>0.546000</td>\n","      <td>0.833704</td>\n","    </tr>\n","    <tr>\n","      <td>70</td>\n","      <td>0.602400</td>\n","      <td>0.792982</td>\n","    </tr>\n","    <tr>\n","      <td>80</td>\n","      <td>0.660600</td>\n","      <td>0.820057</td>\n","    </tr>\n","    <tr>\n","      <td>90</td>\n","      <td>0.704300</td>\n","      <td>0.756601</td>\n","    </tr>\n","    <tr>\n","      <td>100</td>\n","      <td>0.630100</td>\n","      <td>0.840525</td>\n","    </tr>\n","    <tr>\n","      <td>110</td>\n","      <td>0.555800</td>\n","      <td>0.864621</td>\n","    </tr>\n","    <tr>\n","      <td>120</td>\n","      <td>0.626400</td>\n","      <td>0.824904</td>\n","    </tr>\n","    <tr>\n","      <td>130</td>\n","      <td>0.664900</td>\n","      <td>0.829855</td>\n","    </tr>\n","    <tr>\n","      <td>140</td>\n","      <td>0.674800</td>\n","      <td>0.812260</td>\n","    </tr>\n","    <tr>\n","      <td>150</td>\n","      <td>0.655000</td>\n","      <td>0.848054</td>\n","    </tr>\n","    <tr>\n","      <td>160</td>\n","      <td>0.655600</td>\n","      <td>0.798248</td>\n","    </tr>\n","    <tr>\n","      <td>170</td>\n","      <td>0.685400</td>\n","      <td>0.786701</td>\n","    </tr>\n","    <tr>\n","      <td>180</td>\n","      <td>0.712600</td>\n","      <td>0.838528</td>\n","    </tr>\n","    <tr>\n","      <td>190</td>\n","      <td>0.696800</td>\n","      <td>0.770187</td>\n","    </tr>\n","    <tr>\n","      <td>200</td>\n","      <td>0.683600</td>\n","      <td>0.810535</td>\n","    </tr>\n","    <tr>\n","      <td>210</td>\n","      <td>0.664500</td>\n","      <td>0.865055</td>\n","    </tr>\n","    <tr>\n","      <td>220</td>\n","      <td>0.717800</td>\n","      <td>0.824962</td>\n","    </tr>\n","    <tr>\n","      <td>230</td>\n","      <td>0.635300</td>\n","      <td>0.799331</td>\n","    </tr>\n","    <tr>\n","      <td>240</td>\n","      <td>0.647300</td>\n","      <td>0.810953</td>\n","    </tr>\n","    <tr>\n","      <td>250</td>\n","      <td>0.689200</td>\n","      <td>0.809695</td>\n","    </tr>\n","    <tr>\n","      <td>260</td>\n","      <td>0.658000</td>\n","      <td>0.767072</td>\n","    </tr>\n","    <tr>\n","      <td>270</td>\n","      <td>0.648800</td>\n","      <td>0.800345</td>\n","    </tr>\n","    <tr>\n","      <td>280</td>\n","      <td>0.630800</td>\n","      <td>0.793192</td>\n","    </tr>\n","    <tr>\n","      <td>290</td>\n","      <td>0.590500</td>\n","      <td>0.810017</td>\n","    </tr>\n","    <tr>\n","      <td>300</td>\n","      <td>0.679500</td>\n","      <td>0.781074</td>\n","    </tr>\n","    <tr>\n","      <td>310</td>\n","      <td>0.630700</td>\n","      <td>0.754137</td>\n","    </tr>\n","    <tr>\n","      <td>320</td>\n","      <td>0.585500</td>\n","      <td>0.775035</td>\n","    </tr>\n","    <tr>\n","      <td>330</td>\n","      <td>0.629500</td>\n","      <td>0.806531</td>\n","    </tr>\n","    <tr>\n","      <td>340</td>\n","      <td>0.628800</td>\n","      <td>0.791250</td>\n","    </tr>\n","    <tr>\n","      <td>350</td>\n","      <td>0.615800</td>\n","      <td>0.787173</td>\n","    </tr>\n","    <tr>\n","      <td>360</td>\n","      <td>0.636400</td>\n","      <td>0.767064</td>\n","    </tr>\n","    <tr>\n","      <td>370</td>\n","      <td>0.570100</td>\n","      <td>0.805437</td>\n","    </tr>\n","    <tr>\n","      <td>380</td>\n","      <td>0.660000</td>\n","      <td>0.753015</td>\n","    </tr>\n","    <tr>\n","      <td>390</td>\n","      <td>0.630900</td>\n","      <td>0.766189</td>\n","    </tr>\n","    <tr>\n","      <td>400</td>\n","      <td>0.691300</td>\n","      <td>0.771373</td>\n","    </tr>\n","    <tr>\n","      <td>410</td>\n","      <td>0.655600</td>\n","      <td>0.767890</td>\n","    </tr>\n","    <tr>\n","      <td>420</td>\n","      <td>0.618500</td>\n","      <td>0.751617</td>\n","    </tr>\n","    <tr>\n","      <td>430</td>\n","      <td>0.633300</td>\n","      <td>0.754623</td>\n","    </tr>\n","    <tr>\n","      <td>440</td>\n","      <td>0.612900</td>\n","      <td>0.756108</td>\n","    </tr>\n","    <tr>\n","      <td>450</td>\n","      <td>0.583100</td>\n","      <td>0.757931</td>\n","    </tr>\n","    <tr>\n","      <td>460</td>\n","      <td>0.598500</td>\n","      <td>0.758649</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["***** Running Evaluation *****\n","  Num examples = 2592\n","  Batch size = 32\n","***** Running Evaluation *****\n","  Num examples = 2592\n","  Batch size = 32\n","***** Running Evaluation *****\n","  Num examples = 2592\n","  Batch size = 32\n","***** Running Evaluation *****\n","  Num examples = 2592\n","  Batch size = 32\n","***** Running Evaluation *****\n","  Num examples = 2592\n","  Batch size = 32\n","***** Running Evaluation *****\n","  Num examples = 2592\n","  Batch size = 32\n","***** Running Evaluation *****\n","  Num examples = 2592\n","  Batch size = 32\n","***** Running Evaluation *****\n","  Num examples = 2592\n","  Batch size = 32\n","***** Running Evaluation *****\n","  Num examples = 2592\n","  Batch size = 32\n","***** Running Evaluation *****\n","  Num examples = 2592\n","  Batch size = 32\n","***** Running Evaluation *****\n","  Num examples = 2592\n","  Batch size = 32\n","***** Running Evaluation *****\n","  Num examples = 2592\n","  Batch size = 32\n","***** Running Evaluation *****\n","  Num examples = 2592\n","  Batch size = 32\n","***** Running Evaluation *****\n","  Num examples = 2592\n","  Batch size = 32\n","***** Running Evaluation *****\n","  Num examples = 2592\n","  Batch size = 32\n","***** Running Evaluation *****\n","  Num examples = 2592\n","  Batch size = 32\n","***** Running Evaluation *****\n","  Num examples = 2592\n","  Batch size = 32\n","***** Running Evaluation *****\n","  Num examples = 2592\n","  Batch size = 32\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n"]},{"output_type":"execute_result","data":{"text/plain":["TrainOutput(global_step=460, training_loss=0.6370905264564183, metrics={'train_runtime': 1419.8491, 'train_samples_per_second': 10.362, 'train_steps_per_second': 0.324, 'total_flos': 1943022700419696.0, 'train_loss': 0.6370905264564183, 'epoch': 1.0})"]},"metadata":{},"execution_count":18}]},{"cell_type":"markdown","metadata":{"id":"Kr3--ZKNbn1t"},"source":["## Evaluate on Test set"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":263},"id":"hqeWwkSCXaKV","executionInfo":{"status":"ok","timestamp":1644849386908,"user_tz":-60,"elapsed":30852,"user":{"displayName":"Amalia Temneanu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07587986521191248081"}},"outputId":"703665df-169b-4e7b-9c0b-ae22ebd8af54"},"source":["test_preds_raw, test_labels , _ = trainer.predict(test_dataset)\n","test_preds = np.argmax(test_preds_raw, axis=-1)\n","print(classification_report(test_labels, test_preds, digits=3))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["***** Running Prediction *****\n","  Num examples = 6960\n","  Batch size = 32\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='218' max='218' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [218/218 00:30]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0      0.717     0.742     0.729      2320\n","           1      0.667     0.597     0.630      2320\n","           2      0.698     0.748     0.722      2320\n","\n","    accuracy                          0.696      6960\n","   macro avg      0.694     0.696     0.694      6960\n","weighted avg      0.694     0.696     0.694      6960\n","\n"]}]},{"cell_type":"code","source":["df = df_twitter = pd.read_csv('/content/sentimentdata.csv')\n","data = df.processed_text.values.tolist()\n","labels = dataset_dict['test']['labels'][0:536]"],"metadata":{"id":"JWvfuKv7g9By"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["V_encodings = tokenizer(data, truncation=True, padding=True)"],"metadata":{"id":"mw-rIJCmg9EO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["V_dataset = MyDataset(V_encodings, labels)"],"metadata":{"id":"P06Ne892hxww"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test_preds_raw, test_labels , _ = trainer.predict(V_dataset)\n","test_preds = np.argmax(test_preds_raw, axis=-1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":89},"id":"A0ooEgRpdXGf","executionInfo":{"status":"ok","timestamp":1644849523881,"user_tz":-60,"elapsed":4456,"user":{"displayName":"Amalia Temneanu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07587986521191248081"}},"outputId":"369d2d37-ad93-4450-b925-438edb37f754"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["***** Running Prediction *****\n","  Num examples = 536\n","  Batch size = 32\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='235' max='218' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [218/218 02:47]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}}]},{"cell_type":"code","source":["ss = pd.DataFrame(test_preds)\n","df['labelFT'] = ss[0]"],"metadata":{"id":"gP7uOLW-RmiV"},"execution_count":null,"outputs":[]}]}