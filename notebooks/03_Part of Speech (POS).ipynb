{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"03_PartOfSpeech(POS).ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["<a id='Q0'></a>\n","<center> <h1> POSTme!: Tool for Social Media Messaging Optimization </center>\n","<center> <h2> Notebook : Part of Speech Tagging </h2> </center>\n","<p style=\"margin-bottom:1cm;\"></p>\n","<p style=\"margin-bottom:1cm;\"></p>\n","\n","<div style=\"background:#EEEDF5;border-top:0.1cm solid #EF475B;border-bottom:0.1cm solid #EF475B;\">\n","    <div style=\"margin-left: 0.5cm;margin-top: 0.5cm;margin-bottom: 0.5cm;color:#303030\">\n","        <p><strong>Goal:</strong> Parts of speech (POS) are specific lexical categories to which words are assigned, based on their syntactic context and role. Usually, words can fall into one of the following major categories. The process of classifying and labeling POS tags for words called parts of speech tagging or POS tagging. Knowledge about the structure and syntax of language is helpful in many areas like text processing, annotation, and parsing for further operations such as text classification or summarization. The aim of this notebook is to calculate the number of certain POS tags. </p>\n","        \n","\n","[source](https://towardsdatascience.com/a-practitioners-guide-to-natural-language-processing-part-i-processing-understanding-text-9f4abfd13e72)"],"metadata":{"id":"tEVndqZPXIHO"}},{"cell_type":"markdown","source":["### Import Dependencies\n"],"metadata":{"id":"Z2pJdgODXZ58"}},{"cell_type":"code","source":["!pip install contractions\n","!pip install textsearch\n","!pip install tqdm"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"C4G_24Gad6I2","executionInfo":{"status":"ok","timestamp":1643800049860,"user_tz":-60,"elapsed":13537,"user":{"displayName":"sibel yasemin Ozgan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgW4dC0tlp-m0jH3GQroruKuA9g6a2UtxNPgTB7OZ8=s64","userId":"01680209359633403782"}},"outputId":"161f5d96-2155-4d57-f13d-3471e566e75b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting contractions\n","  Downloading contractions-0.1.66-py2.py3-none-any.whl (8.0 kB)\n","Collecting textsearch>=0.0.21\n","  Downloading textsearch-0.0.21-py2.py3-none-any.whl (7.5 kB)\n","Collecting anyascii\n","  Downloading anyascii-0.3.0-py3-none-any.whl (284 kB)\n","\u001b[?25l\r\u001b[K     |█▏                              | 10 kB 17.4 MB/s eta 0:00:01\r\u001b[K     |██▎                             | 20 kB 24.6 MB/s eta 0:00:01\r\u001b[K     |███▌                            | 30 kB 30.7 MB/s eta 0:00:01\r\u001b[K     |████▋                           | 40 kB 35.1 MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 51 kB 25.2 MB/s eta 0:00:01\r\u001b[K     |███████                         | 61 kB 28.3 MB/s eta 0:00:01\r\u001b[K     |████████                        | 71 kB 28.1 MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 81 kB 23.0 MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 92 kB 25.0 MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 102 kB 27.0 MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 112 kB 27.0 MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 122 kB 27.0 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 133 kB 27.0 MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 143 kB 27.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 153 kB 27.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 163 kB 27.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 174 kB 27.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 184 kB 27.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 194 kB 27.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 204 kB 27.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 215 kB 27.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 225 kB 27.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 235 kB 27.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 245 kB 27.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 256 kB 27.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 266 kB 27.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 276 kB 27.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 284 kB 27.0 MB/s \n","\u001b[?25hCollecting pyahocorasick\n","  Downloading pyahocorasick-1.4.2.tar.gz (321 kB)\n","\u001b[?25l\r\u001b[K     |█                               | 10 kB 26.1 MB/s eta 0:00:01\r\u001b[K     |██                              | 20 kB 34.9 MB/s eta 0:00:01\r\u001b[K     |███                             | 30 kB 39.8 MB/s eta 0:00:01\r\u001b[K     |████                            | 40 kB 41.5 MB/s eta 0:00:01\r\u001b[K     |█████                           | 51 kB 44.6 MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 61 kB 49.5 MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 71 kB 52.2 MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 81 kB 54.9 MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 92 kB 58.0 MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 102 kB 60.6 MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 112 kB 60.6 MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 122 kB 60.6 MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 133 kB 60.6 MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 143 kB 60.6 MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 153 kB 60.6 MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 163 kB 60.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 174 kB 60.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 184 kB 60.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 194 kB 60.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 204 kB 60.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 215 kB 60.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 225 kB 60.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 235 kB 60.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 245 kB 60.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 256 kB 60.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 266 kB 60.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 276 kB 60.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 286 kB 60.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 296 kB 60.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 307 kB 60.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 317 kB 60.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 321 kB 60.6 MB/s \n","\u001b[?25hBuilding wheels for collected packages: pyahocorasick\n","  Building wheel for pyahocorasick (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pyahocorasick: filename=pyahocorasick-1.4.2-cp37-cp37m-linux_x86_64.whl size=85455 sha256=ebe22f55e08854548749d5f3db951b704759d439bad817f9a37d173e86c8a797\n","  Stored in directory: /root/.cache/pip/wheels/25/19/a6/8f363d9939162782bb8439d886469756271abc01f76fbd790f\n","Successfully built pyahocorasick\n","Installing collected packages: pyahocorasick, anyascii, textsearch, contractions\n","Successfully installed anyascii-0.3.0 contractions-0.1.66 pyahocorasick-1.4.2 textsearch-0.0.21\n","Requirement already satisfied: textsearch in /usr/local/lib/python3.7/dist-packages (0.0.21)\n","Requirement already satisfied: pyahocorasick in /usr/local/lib/python3.7/dist-packages (from textsearch) (1.4.2)\n","Requirement already satisfied: anyascii in /usr/local/lib/python3.7/dist-packages (from textsearch) (0.3.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (4.62.3)\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nX_lw4fjW8EQ"},"outputs":[],"source":["import nltk\n","import contractions\n","import re\n","import tqdm\n","\n","import pandas as pd\n","import numpy as np\n","\n","import textblob\n","\n","from google.colab import drive #to import and export data directly"]},{"cell_type":"code","source":["nltk.download(\"punkt\")\n","nltk.download('averaged_perceptron_tagger')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xXVUeAvBXh64","executionInfo":{"status":"ok","timestamp":1643800051615,"user_tz":-60,"elapsed":635,"user":{"displayName":"sibel yasemin Ozgan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgW4dC0tlp-m0jH3GQroruKuA9g6a2UtxNPgTB7OZ8=s64","userId":"01680209359633403782"}},"outputId":"57ff8343-5639-4bac-8704-c7ff91c61a9f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n","[nltk_data] Downloading package averaged_perceptron_tagger to\n","[nltk_data]     /root/nltk_data...\n","[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":4}]},{"cell_type":"markdown","source":["# POS tagging\n","\n","For this task, we will only count the number of specific parts of speech and categorize them under certain groups. As an example, singular nouns (NN), plural nouns(NNS), singular proper nouns(NNP), and plural proper nouns (NNPS) will be categorized as nouns. \n","\n","## List of Part-of-Speech Tags\n","\n","| POS Tag | Description | Example |\n","|---------|---------------------------------------|-----------------------------------------|\n","| CC | coordinating conjunction | and |\n","| CD | cardinal number | 1, third |\n","| DT | determiner | the |\n","| EX | existential there | there is |\n","| FW | foreign word | d’hoevre |\n","| IN | preposition/subordinating conjunction | in, of, like |\n","| JJ | adjective | big |\n","| JJR | adjective, comparative | bigger |\n","| JJS | adjective, superlative | biggest |\n","| LS | list marker | 1) |\n","| MD | modal | could, will |\n","| NN | noun, singular or mass | door |\n","| NNS | noun plural | doors |\n","| NNP | proper noun, singular | John |\n","| NNPS | proper noun, plural | Vikings |\n","| PDT | predeterminer | both the boys |\n","| POS | possessive ending | friend‘s |\n","| PRP | personal pronoun | I, he, it |\n","| PRP\\$ | possessive pronoun | my, his |\n","| RB | adverb | however, usually, naturally, here, good |\n","| RBR | adverb, comparative | better |\n","| RBS | adverb, superlative | best |\n","| RP | particle | give up |\n","| TO | to | to go, to him |\n","| UH | interjection | uhhuhhuhh |\n","| VB | verb, base form | take |\n","| VBD | verb, past tense | took |\n","| VBG | verb, gerund/present participle | taking |\n","| VBN | verb, past participle | taken |\n","| VBP | verb, sing. present, non-3d | take |\n","| VBZ | verb, 3rd person sing. present | takes |\n","| WDT | wh-determiner | which |\n","| WP | wh-pronoun | who, what |\n","| WP\\$ | possessive wh-pronoun | whose |\n","| WRB | wh-abverb | where, when |\n","\n","[Source](https://www.ling.upenn.edu/courses/Fall_2003/ling001/penn_treebank_pos.html)"],"metadata":{"id":"Ccen6FVEpINk"}},{"cell_type":"code","source":["pos_family = {\n","    'noun' : ['NN','NNS','NNP','NNPS'],\n","    'pron' : ['PRP','PRP$','WP','WP$'],\n","    'verb' : ['VB','VBD','VBG','VBN','VBP','VBZ'],\n","    'adj' :  ['JJ','JJR','JJS'],\n","    'adv' :  ['RB','RBR','RBS','WRB']\n","}"],"metadata":{"id":"I_tw3WKNXoiV"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["In order to mark up the words in a text(corpus) as corresponding to a particular part of speech we use the TextBlob library. TextBlob is an open-source library for processing textual data and performing NLP tasks with ease. Check out the documentation here: [TextBlob](https://textblob.readthedocs.io/en/dev/)\n","\n"],"metadata":{"id":"d8qncdgvqfLA"}},{"cell_type":"code","source":["# function to check and get the part of speech tag count of a words in a given sentence\n","# note this may take some time to execute on larger corpora\n","\n","def check_pos_tag(x, flag):\n","    cnt = 0\n","    try:\n","        wiki = textblob.TextBlob(x)\n","        for tup in wiki.tags:\n","            ppo = list(tup)[1]\n","            if ppo in pos_family[flag]:\n","                cnt += 1\n","    except:\n","        pass\n","    return cnt"],"metadata":{"id":"vY2VpUBRZfzi"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Twitter Data"],"metadata":{"id":"JpTPtvZkbZS2"}},{"cell_type":"code","source":["df_twitter.info()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mSDHeimIbduk","executionInfo":{"status":"ok","timestamp":1643800054396,"user_tz":-60,"elapsed":206,"user":{"displayName":"sibel yasemin Ozgan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgW4dC0tlp-m0jH3GQroruKuA9g6a2UtxNPgTB7OZ8=s64","userId":"01680209359633403782"}},"outputId":"b5f6149a-03ac-41dd-9a10-7ee2f3c3f0f5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 268 entries, 0 to 267\n","Data columns (total 23 columns):\n"," #   Column                                       Non-Null Count  Dtype  \n","---  ------                                       --------------  -----  \n"," 0   Unnamed: 0                                   268 non-null    int64  \n"," 1   data_id                                      268 non-null    int64  \n"," 2   data_text                                    268 non-null    object \n"," 3   data_non_public_metrics_impression_count     268 non-null    int64  \n"," 4   data_non_public_metrics_url_link_clicks      210 non-null    float64\n"," 5   data_non_public_metrics_user_profile_clicks  268 non-null    int64  \n"," 6   data_organic_metrics_impression_count        268 non-null    int64  \n"," 7   data_organic_metrics_like_count              268 non-null    int64  \n"," 8   data_organic_metrics_reply_count             268 non-null    int64  \n"," 9   data_organic_metrics_retweet_count           268 non-null    int64  \n"," 10  data_organic_metrics_url_link_clicks         210 non-null    float64\n"," 11  data_organic_metrics_user_profile_clicks     268 non-null    int64  \n"," 12  data_public_metrics_like_count               268 non-null    int64  \n"," 13  data_public_metrics_quote_count              268 non-null    int64  \n"," 14  data_public_metrics_reply_count              268 non-null    int64  \n"," 15  data_public_metrics_retweet_count            268 non-null    int64  \n"," 16  data_created_at                              267 non-null    object \n"," 17  data_in_reply_to_user_id                     8 non-null      float64\n"," 18  norm_twitter_posts                           268 non-null    object \n"," 19  flesch_reading_ease_score                    268 non-null    float64\n"," 20  automated_readability_index                  268 non-null    float64\n"," 21  Polarity                                     268 non-null    float64\n"," 22  Subjectivity                                 268 non-null    float64\n","dtypes: float64(7), int64(13), object(3)\n","memory usage: 48.3+ KB\n"]}]},{"cell_type":"code","source":["feature_col = 'data_text'"],"metadata":{"id":"-WffrRU-b2Uf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_twitter['noun_count'] = df_twitter[feature_col].apply(lambda x: check_pos_tag(x, 'noun'))"],"metadata":{"id":"iMk1AnLOb6HV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_twitter['verb_count'] = df_twitter[feature_col].apply(lambda x: check_pos_tag(x, 'verb'))"],"metadata":{"id":"luJoQ123cFi_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_twitter['adj_count'] = df_twitter[feature_col].apply(lambda x: check_pos_tag(x, 'adj'))"],"metadata":{"id":"vGij7QcYcKxg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_twitter['adv_count'] = df_twitter[feature_col].apply(lambda x: check_pos_tag(x, 'adv'))"],"metadata":{"id":"1WuUgyoPcSyr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_twitter['pron_count'] = df_twitter[feature_col].apply(lambda x: check_pos_tag(x, 'pron'))"],"metadata":{"id":"2Dwt8drwcX8T"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["twitter_pos = df_twitter[['data_id','noun_count', 'verb_count','adj_count', 'adv_count', 'pron_count']]"],"metadata":{"id":"bU4Mvs2cfNLq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["twitter_pos.info()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EKc_jSdCMOaQ","executionInfo":{"status":"ok","timestamp":1643800065546,"user_tz":-60,"elapsed":13,"user":{"displayName":"sibel yasemin Ozgan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgW4dC0tlp-m0jH3GQroruKuA9g6a2UtxNPgTB7OZ8=s64","userId":"01680209359633403782"}},"outputId":"706afc84-ea12-4183-db63-564eb6b2b976"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 268 entries, 0 to 267\n","Data columns (total 6 columns):\n"," #   Column      Non-Null Count  Dtype\n","---  ------      --------------  -----\n"," 0   data_id     268 non-null    int64\n"," 1   noun_count  268 non-null    int64\n"," 2   verb_count  268 non-null    int64\n"," 3   adj_count   268 non-null    int64\n"," 4   adv_count   268 non-null    int64\n"," 5   pron_count  268 non-null    int64\n","dtypes: int64(6)\n","memory usage: 12.7 KB\n"]}]},{"cell_type":"markdown","source":["### Linkedin Data"],"metadata":{"id":"wWYEc9BybXHu"}},{"cell_type":"code","source":["df_linkedin.info()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uyxrNkMdMwKY","executionInfo":{"status":"ok","timestamp":1643800310200,"user_tz":-60,"elapsed":246,"user":{"displayName":"sibel yasemin Ozgan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgW4dC0tlp-m0jH3GQroruKuA9g6a2UtxNPgTB7OZ8=s64","userId":"01680209359633403782"}},"outputId":"ed387d07-d4d5-487b-de04-f271f475aa2b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 273 entries, 0 to 272\n","Data columns (total 21 columns):\n"," #   Column                       Non-Null Count  Dtype  \n","---  ------                       --------------  -----  \n"," 0   Unnamed: 0                   273 non-null    int64  \n"," 1   DateTime                     273 non-null    object \n"," 2   LinkeInPage                  273 non-null    object \n"," 3   DataID                       273 non-null    int64  \n"," 4   Tags                         97 non-null     object \n"," 5   PostCampaign                 0 non-null      float64\n"," 6   PostType                     273 non-null    object \n"," 7   PostMessage                  273 non-null    object \n"," 8   Reactions                    273 non-null    int64  \n"," 9   Impressions                  273 non-null    int64  \n"," 10  Engagement                   273 non-null    float64\n"," 11  Clicks                       273 non-null    int64  \n"," 12  Shares                       273 non-null    int64  \n"," 13  Comments                     273 non-null    int64  \n"," 14  Date                         273 non-null    object \n"," 15  Time                         273 non-null    object \n"," 16  norm_linkedin_posts          268 non-null    object \n"," 17  flesch_reading_ease_score    273 non-null    float64\n"," 18  automated_readability_index  273 non-null    float64\n"," 19  Polarity                     273 non-null    float64\n"," 20  Subjectivity                 273 non-null    float64\n","dtypes: float64(6), int64(7), object(8)\n","memory usage: 44.9+ KB\n"]}]},{"cell_type":"code","source":["feature_col = \"PostMessage\""],"metadata":{"id":"5mxCK1aPIniD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_linkedin['noun_count'] = df_linkedin[feature_col].apply(lambda x: check_pos_tag(x, 'noun'))"],"metadata":{"id":"gM4oK98jM7gs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_linkedin['verb_count'] = df_linkedin[feature_col].apply(lambda x: check_pos_tag(x, 'verb'))"],"metadata":{"id":"c3A8j5wPM7gt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_linkedin['adj_count'] = df_linkedin[feature_col].apply(lambda x: check_pos_tag(x, 'adj'))"],"metadata":{"id":"dsNnnSQ-M7gt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_linkedin['adv_count'] = df_linkedin[feature_col].apply(lambda x: check_pos_tag(x, 'adv'))"],"metadata":{"id":"sGyHBN_fM7gt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_linkedin['pron_count'] = df_linkedin[feature_col].apply(lambda x: check_pos_tag(x, 'pron'))"],"metadata":{"id":"TJIt9jsBM7gt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["linkedin_pos = df_linkedin[['DataID','noun_count', 'verb_count','adj_count', 'adv_count', 'pron_count']]"],"metadata":{"id":"oCcs38JOM7gt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["linkedin_pos = linkedin_pos.rename(columns={\"DataID\":\"data_id\"})"],"metadata":{"id":"3UrdcY88JBI7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["linkedin_pos.info()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1643800467407,"user_tz":-60,"elapsed":198,"user":{"displayName":"sibel yasemin Ozgan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgW4dC0tlp-m0jH3GQroruKuA9g6a2UtxNPgTB7OZ8=s64","userId":"01680209359633403782"}},"outputId":"e1e67ade-ba69-4b72-e0e5-6922edefb35d","id":"teqIc2IhM7gu"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 273 entries, 0 to 272\n","Data columns (total 6 columns):\n"," #   Column      Non-Null Count  Dtype\n","---  ------      --------------  -----\n"," 0   data_id     273 non-null    int64\n"," 1   noun_count  273 non-null    int64\n"," 2   verb_count  273 non-null    int64\n"," 3   adj_count   273 non-null    int64\n"," 4   adv_count   273 non-null    int64\n"," 5   pron_count  273 non-null    int64\n","dtypes: int64(6)\n","memory usage: 12.9 KB\n"]}]}]}